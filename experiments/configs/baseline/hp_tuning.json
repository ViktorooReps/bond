{
    "output": "logs/hp_tune.log",
    "config_name": "hp-tuning",
    "memory_needed": 7.0,
    "command": "python train.py",
    "args": [
        "--use_adaptive_scheduler",
        ["--logging=50", "--logging=100", "--logging=250"],
        ["--adaptive_scheduler_patience=5", "--adaptive_scheduler_patience=3", "--adaptive_scheduler_patience=7"],
        "--framework=supervised",
        "--resfile=res.final.txt",
        "--dataset=conll03",
        "--dataset_type=gold/train",
        "--model_type=roberta",
        "--model_name=roberta-base",
        "--gradient_accumulation_steps=1",
        "--max_seq_len=512",
        ["--batch_size=4", "--batch_size=8", "--batch_size=16"],
        "--head_dropout=0.3",
        "--bert_dropout=0.1",
        ["--learning_rate=1e-05", "--learning_rate=5e-05", "--learning_rate=2.5e-05"],
        "--weight_decay=1e-04",
        "--adam_epsilon=1e-06",
        "--adam_beta1=0.9",
        "--adam_beta2=0.999",
        "--no_entity_weight=0.7",
        "--warmup_proportion=0.2",
        ["--ner_fit_epochs=5", "--ner_fit_epochs=10", "--ner_fit_epochs=15"],
        "--seed=42"
    ]
}