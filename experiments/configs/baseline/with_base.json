{
    "output": "logs/based.log",
    "config_name": "based",
    "memory_needed": 7.0,
    "command": "python train.py",
    "args": [
        ["--base_distributions_file=supervised_on_conll03_merged_0.05_roberta-base_seq512_2folds.pkl",
          "--base_distributions_file=supervised_on_conll03_merged_0.05_roberta-base_seq512_3folds.pkl",
          "--base_distributions_file=supervised_on_conll03_merged_0.05_roberta-base_seq512_5folds.pkl",
          "--base_distributions_file=supervised_on_conll03_merged_0.05_roberta-base_seq512_10folds.pkl"
        ],
        "--logging=10000000",
        "--framework=supervised",
        "--resfile=res.final.txt",
        "--dataset=conll03",
        "--dataset_type=gold/train",
        "--add_gold_labels=0.05",
        "--model_type=roberta",
        "--model_name=roberta-base",
        "--gradient_accumulation_steps=1",
        "--max_seq_len=512",
        "--batch_size=4",
        "--head_dropout=0.3",
        "--bert_dropout=0.1",
        "--learning_rate=5e-05",
        "--weight_decay=1e-04",
        "--adam_epsilon=1e-06",
        "--adam_beta1=0.9",
        "--adam_beta2=0.999",
        "--no_entity_weight=0.7",
        "--warmup_proportion=0.2",
        "--ner_fit_epochs=5",
        "--use_linear_scheduler",
        "--seed=42"
    ]
}