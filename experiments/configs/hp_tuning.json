{
    "output": "logs/hp_tune.log",
    "config_name": "hp-tuning",
    "memory_needed": 10.0,
    "command": "python train.py",
    "args": [
        "--logging=10000000",
        "--framework=supervised",
        "--resfile=res.final.txt",
        "--dataset=conll03",
        "--dataset_type=gold/train",
        "--model_type=roberta",
        "--model_name=roberta-base",
        "--gradient_accumulation_steps=1",
        "--max_seq_len=512",
        "--batch_size=4",
        ["--head_dropout=0.3", "--head_dropout=0.4", "--head_dropout=0.5", "--head_dropout=0.6", "--head_dropout=0.7", "--head_dropout=0.8", "--head_dropout=0.9"],
        ["--bert_dropout=0.05", "--bert_dropout=0.1", "--bert_dropout=0.15", "--bert_dropout=0.2"],
        "--learning_rate=5e-05",
        "--weight_decay=1e-04",
        "--adam_epsilon=1e-06",
        "--adam_beta1=0.9",
        "--adam_beta2=0.999",
        "--no_entity_weight=0.7",
        "--warmup_proportion=0.2",
        "--ner_fit_epochs=5",
        "--use_linear_scheduler",
        "--seed=42"
    ]
}