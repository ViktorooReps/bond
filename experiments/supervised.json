[
  {
    "script": "train.py",
    "save_output": "logs/supervised-baseline/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=2",
      "--max_seq_len=128",
      "--batch_size=8",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-no-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=1",
      "--max_seq_len=128",
      "--batch_size=8",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-extra-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=4",
      "--max_seq_len=128",
      "--batch_size=8",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-larger-seq-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=2",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-larger-seq-no-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=1",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-larger-seq-extra-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=4",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-extra-large-seq-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=2",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-extra-large-seq-no-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=1",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-extra-large-seq-extra-accumulation/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-baseline",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta-crf",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=4",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  }
]