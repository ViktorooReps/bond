[
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq256-bs16/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs16",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=4",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq512-bs16/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs16",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=8",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq256-bs32/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs32",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=8",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq512-bs32/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs32",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=16",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq256-bs64/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs64",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=16",
      "--max_seq_len=256",
      "--batch_size=4",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  },
  {
    "script": "train.py",
    "save_output": "logs/supervised-seq512-bs64/script_output.log",
    "args": [
      "--framework=supervised",
      "--experiment_name=supervised-seq256-bs64",
      "--dataset=conll03",
      "--dataset_type=gold/train",
      "--model_type=roberta",
      "--model_name=roberta-base",
      "--gradient_accumulation_steps=32",
      "--max_seq_len=512",
      "--batch_size=2",
      "--add_lstm",
      "--lstm_hidden_size=512",
      "--lstm_num_layers=1",
      "--lstm_dropout=0.5",
      "--add_crf",
      "--head_dropout=0.5",
      "--bert_dropout=0.1",
      "--subword_repr_size=512",
      "--head_learning_rate=5e-04",
      "--bert_learning_rate=5e-05",
      "--weight_decay=1e-04",
      "--adam_epsilon=1e-06",
      "--adam_beta1=0.9",
      "--adam_beta2=0.999",
      "--warmup_proportion=0.1",
      "--ner_fit_epochs=6",
      "--use_linear_scheduler",
      "--seed=42"
    ]
  }
]